{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b58aa633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a6f0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'corpus_all.txt'  # Replace with the actual path to your text file\n",
    "\n",
    "lines = []  # Empty list to store the lines\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            lines.append(line.strip())  # Append the line to the list, removing any leading/trailing whitespace\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "\n",
    "#file_path = 'corpus_all.txt'  # Replace with the actual path to your text file\n",
    "first_words = []  # Empty list to store the first words\n",
    "\n",
    "try:\n",
    "    for line in lines:\n",
    "        words = line.strip().split()  # Split the line into words\n",
    "        if words:\n",
    "            first_word = words[0]  # Get the first word\n",
    "            first_words.append(first_word)  # Append the first word to the list\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "\n",
    "\n",
    "# Define the status levels\n",
    "status_levels = [\"happy\",\"angry\",\"fear\",\"disgust\",\"sad\",\"surprise\",]\n",
    "\n",
    "# Initialize a list to store the extracted status levels and sentences\n",
    "extracted_data = []\n",
    "\n",
    "# Iterate over the texts\n",
    "for text in lines:\n",
    "    # Initialize variables to store the extracted status level and sentence\n",
    "    status = \"\"\n",
    "    sentence = \"\"\n",
    "\n",
    "    # Iterate over the status levels\n",
    "    for level in status_levels:\n",
    "        if level in text:\n",
    "            # Split the text based on the status level\n",
    "            split_text = text.split(level, 1)\n",
    "\n",
    "            # Extract the status level and sentence\n",
    "            status = level\n",
    "            sentence = split_text[1].strip()\n",
    "            break\n",
    "\n",
    "    # Append the extracted status level and sentence to the list\n",
    "    extracted_data.append({\"Status\": status, \"Sentence\": sentence})\n",
    "    \n",
    "dataset = pd.DataFrame(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9616e491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>বরাবর, মাননীয় প্রধানমন্ত্রী গণপ্রজাতন্ত্রী বা...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>তদন্ত করে লাভ কী ? কোন দিন কোন তদন্তের পর কিছু...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>দেশকি মধ্যম আয়ের দেশে রুপান্তর হচ্ছে নাকি মগের...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>আমি গর্বিত আমি মুসলিম। আমি সংগ্রামী। আমি যোদ্ধ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>রাতের বেলা আবার কিসের সকাল।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>surprise</td>\n",
       "      <td>ভারতে প্রতিদিন ১৮ টা রেপ কেইস এন্ট্রি হয়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>surprise</td>\n",
       "      <td>এই কি স্বাধীন দেশ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>sad</td>\n",
       "      <td>স্বাধীন দেশের নাগরিক হয়ে ও আজ আমরা পরাধীন।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>angry</td>\n",
       "      <td>চুদলাম দাদা পয়সা নাই</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>sad</td>\n",
       "      <td>আমরা মানুষের মত হয়ে বাচতে চায়,পরাধীন হয়ে নয়</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6289 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Status                                           Sentence\n",
       "0          sad  বরাবর, মাননীয় প্রধানমন্ত্রী গণপ্রজাতন্ত্রী বা...\n",
       "1          sad  তদন্ত করে লাভ কী ? কোন দিন কোন তদন্তের পর কিছু...\n",
       "2        angry  দেশকি মধ্যম আয়ের দেশে রুপান্তর হচ্ছে নাকি মগের...\n",
       "3        happy  আমি গর্বিত আমি মুসলিম। আমি সংগ্রামী। আমি যোদ্ধ...\n",
       "4        angry                        রাতের বেলা আবার কিসের সকাল।\n",
       "...        ...                                                ...\n",
       "6284  surprise           ভারতে প্রতিদিন ১৮ টা রেপ কেইস এন্ট্রি হয়\n",
       "6285  surprise                                  এই কি স্বাধীন দেশ\n",
       "6286       sad         স্বাধীন দেশের নাগরিক হয়ে ও আজ আমরা পরাধীন।\n",
       "6287     angry                               চুদলাম দাদা পয়সা নাই\n",
       "6288       sad        আমরা মানুষের মত হয়ে বাচতে চায়,পরাধীন হয়ে নয়\n",
       "\n",
       "[6289 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3476cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pinash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pinash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Replace with Bengali stopwords\n",
    "bengali_stopwords = set([\"এই\", \"কি\", \"হয়\"])\n",
    "\n",
    "# Assuming your DataFrame is called 'df'\n",
    "X = dataset['Sentence']\n",
    "y = dataset['Status']\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens if t.isalpha() and t not in bengali_stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing to the sentences\n",
    "X_preprocessed = X.apply(preprocess_text)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "153400cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            sad\n",
       "1            sad\n",
       "2          angry\n",
       "3          happy\n",
       "4          angry\n",
       "          ...   \n",
       "6284    surprise\n",
       "6285    surprise\n",
       "6286         sad\n",
       "6287       angry\n",
       "6288         sad\n",
       "Name: Status, Length: 6289, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e644d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "703773da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9817e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3386327503974563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.28      0.19      0.22       268\n",
      "     disgust       0.15      0.01      0.03       141\n",
      "        fear       0.42      0.08      0.13        66\n",
      "       happy       0.37      0.81      0.50       391\n",
      "         sad       0.28      0.19      0.22       278\n",
      "    surprise       0.00      0.00      0.00       114\n",
      "\n",
      "    accuracy                           0.34      1258\n",
      "   macro avg       0.25      0.21      0.18      1258\n",
      "weighted avg       0.27      0.34      0.26      1258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d1933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bad37620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have loaded your dataset into a pandas DataFrame named 'df'\n",
    "# X should contain the features (in this case, the 'Sentence' column) and y should contain the target class labels (the 'Status' column)\n",
    "X = dataset['Sentence']\n",
    "y = dataset['Status']\n",
    "\n",
    "# Create a TfidfVectorizer to convert text to numerical features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Create an instance of the SMOTE class\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class (fear)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_vectorized, y)\n",
    "\n",
    "# Convert the resampled data back to a DataFrame\n",
    "df = pd.DataFrame({'Status': y_resampled, 'Sentence': X_resampled})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58f24312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>(0, 3085)\\t0.04325065094600315\\n  (0, 2863)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>(0, 1527)\\t0.13503058341724922\\n  (0, 3140)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>(0, 2695)\\t0.36675405908123854\\n  (0, 3283)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>(0, 1078)\\t0.3174361850159315\\n  (0, 1700)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>(0, 3139)\\t0.815637800513949\\n  (0, 1157)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11425</th>\n",
       "      <td>surprise</td>\n",
       "      <td>(0, 3221)\\t0.17982368306812407\\n  (0, 2893)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>surprise</td>\n",
       "      <td>(0, 2844)\\t0.28862964104909306\\n  (0, 1868)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>surprise</td>\n",
       "      <td>(0, 1543)\\t0.23329132119279034\\n  (0, 1097)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>surprise</td>\n",
       "      <td>(0, 3314)\\t0.020292737135870875\\n  (0, 2655)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>surprise</td>\n",
       "      <td>(0, 1165)\\t0.10130664558951535\\n  (0, 1147)\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11430 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Status                                           Sentence\n",
       "0           sad    (0, 3085)\\t0.04325065094600315\\n  (0, 2863)\\...\n",
       "1           sad    (0, 1527)\\t0.13503058341724922\\n  (0, 3140)\\...\n",
       "2         angry    (0, 2695)\\t0.36675405908123854\\n  (0, 3283)\\...\n",
       "3         happy    (0, 1078)\\t0.3174361850159315\\n  (0, 1700)\\t...\n",
       "4         angry    (0, 3139)\\t0.815637800513949\\n  (0, 1157)\\t0...\n",
       "...         ...                                                ...\n",
       "11425  surprise    (0, 3221)\\t0.17982368306812407\\n  (0, 2893)\\...\n",
       "11426  surprise    (0, 2844)\\t0.28862964104909306\\n  (0, 1868)\\...\n",
       "11427  surprise    (0, 1543)\\t0.23329132119279034\\n  (0, 1097)\\...\n",
       "11428  surprise    (0, 3314)\\t0.020292737135870875\\n  (0, 2655)...\n",
       "11429  surprise    (0, 1165)\\t0.10130664558951535\\n  (0, 1147)\\...\n",
       "\n",
       "[11430 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b791ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have already processed the dataset and stored it in a DataFrame called 'df'\n",
    "# X should be dense numerical arrays representing the features\n",
    "x_new = df['Sentence'].astype(str).tolist()  # Assuming the \"Sentence\" column contains dense numerical arrays\n",
    "\n",
    "y_new = df['Status']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff1edb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_vectorized_new = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d3fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
