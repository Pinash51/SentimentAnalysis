{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3120639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import re as sub\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "28abf640",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'corpus_all.txt'  # Replace with the actual path to your text file\n",
    "\n",
    "lines = []  # Empty list to store the lines\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            lines.append(line.strip())  # Append the line to the list, removing any leading/trailing whitespace\n",
    "    with open('stopwords-bn.txt', 'r', encoding='utf-8') as test:\n",
    "        stopwords_bn = test.readlines()\n",
    "        # the above stopwords contains newline \\n\n",
    "        stop_bn = []\n",
    "\n",
    "        for word in stopwords_bn:\n",
    "            stop_bn.append(word.rstrip(\"\\r\\n\"))\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "\n",
    "#file_path = 'corpus_all.txt'  # Replace with the actual path to your text file\n",
    "first_words = []  # Empty list to store the first words\n",
    "\n",
    "try:\n",
    "    for line in lines:\n",
    "        words = line.strip().split()  # Split the line into words\n",
    "        if words:\n",
    "            first_word = words[0]  # Get the first word\n",
    "            first_words.append(first_word)  # Append the first word to the list\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "\n",
    "\n",
    "# Define the status levels\n",
    "status_levels = [\"happy\",\"angry\",\"fear\",\"disgust\",\"sad\",\"surprise\",]\n",
    "\n",
    "# Initialize a list to store the extracted status levels and sentences\n",
    "extracted_data = []\n",
    "\n",
    "# Iterate over the texts\n",
    "for text in lines:\n",
    "    # Initialize variables to store the extracted status level and sentence\n",
    "    status = \"\"\n",
    "    sentence = \"\"\n",
    "\n",
    "    # Iterate over the status levels\n",
    "    for level in status_levels:\n",
    "        if level in text:\n",
    "            # Split the text based on the status level\n",
    "            split_text = text.split(level, 1)\n",
    "\n",
    "            # Extract the status level and sentence\n",
    "            status = level\n",
    "            sentence = split_text[1].strip()\n",
    "            break\n",
    "\n",
    "    # Append the extracted status level and sentence to the list\n",
    "    extracted_data.append({\"Status\": status, \"Sentence\": sentence})\n",
    "    \n",
    "df = pd.DataFrame(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7b759df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_pre_processing(text):\n",
    "    #remove stop words from the text\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_bn)\n",
    "    #remove punctuation from the text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    #remove numbers from the text\n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    #remove extra spaces from the text\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['Sentence'] = df['Sentence'].apply(text_pre_processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6349b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>বরবর মননয পরধনমনতর গণপরজতনতর বলদশ সরকর মননয পর...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>তদনত লভ তদনতর হয়ছ মন রজনতক শকতর তদনত পরব সমনয ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>দশক মধযম আয়র দশ রপনতর মগর মলকর দশ পরনত হচছ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>গরবত মসলম সগরম যদধ চর রণবর আললহ ছর নচ শর নরয় ত...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>রতর বল কসর সকল</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>surprise</td>\n",
       "      <td>ভরত পরতদন ১৮ ট রপ কইস এনটর</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>surprise</td>\n",
       "      <td>সবধন দশ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>sad</td>\n",
       "      <td>সবধন দশর নগরক হয় পরধন</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>angry</td>\n",
       "      <td>চদলম দদ পয়স</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>sad</td>\n",
       "      <td>মনষর মত হয় বচত চয়পরধন হয়</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6289 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Status                                           Sentence\n",
       "0          sad  বরবর মননয পরধনমনতর গণপরজতনতর বলদশ সরকর মননয পর...\n",
       "1          sad  তদনত লভ তদনতর হয়ছ মন রজনতক শকতর তদনত পরব সমনয ...\n",
       "2        angry         দশক মধযম আয়র দশ রপনতর মগর মলকর দশ পরনত হচছ\n",
       "3        happy  গরবত মসলম সগরম যদধ চর রণবর আললহ ছর নচ শর নরয় ত...\n",
       "4        angry                                     রতর বল কসর সকল\n",
       "...        ...                                                ...\n",
       "6284  surprise                         ভরত পরতদন ১৮ ট রপ কইস এনটর\n",
       "6285  surprise                                            সবধন দশ\n",
       "6286       sad                              সবধন দশর নগরক হয় পরধন\n",
       "6287     angry                                        চদলম দদ পয়স\n",
       "6288       sad                           মনষর মত হয় বচত চয়পরধন হয়\n",
       "\n",
       "[6289 rows x 2 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cf1a5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4ac0d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'বরবর মননয পরধনমনতর গণপরজতনতর বলদশ সরকর মননয পরধনমনতর সবপনর ডজটল বলদশর সবপন বক ললনকর একজন ছতর শত সহসর আশ দশর এক অকততম ভলবস নজক দশর যগয গড তলর এক তবর আকঙকষ ভরত হযছলম নজ হত পরতষঠত দশর অনযতম বশববদযলয যশর বজঞন পরযকত বশববদযলয ডজটল বলদশ গডত ধরণর পরযকত বশববদযলয পরতষঠ নসনদহ দশ পরচলনর বচকষণতর পরচয বহন কর যশর বসর সবপনর পরতষঠন শত শত টক বনযগ দহত উজড কর অতযনত দখর সথ বশববদযলয জবনর সচনলগন অনভব করছ য পওযর আননদ শকষরথদর মনপরন উজড পডলখ কথ বপরত কমলমত শকষরথর সদ দনতপত পরণ নশর হমক শললতহনর গলন ছতরতত বতল হমক নয সমমনত শকষকদর মরত যওয গল কট ফলর হমক পরণ নশর হমক কটকত নযমত ঘটন মননয পরধনমনতর শকষরথর শকষকদর পতমতর মত সমমন একজন চতরথ শরণর করমচরর শকষকদর নযমত ঘটনর শকর ডজটল বলদশর সবপন পক হনদর বহনর মত হন যয চখর ছতর বনর সললতহনর হয পরতবদ বহষকর শকষরথদর ভষ আনদলন মকতযদধর বভষকময গলর কথ সশসনর বলদশ আদরশ বশববদযলয বশববদযলযর পরশসনর পষ সনতরস মদক বযবসয শকষকদর লঞচত কর ছতরদর জবন ছনমন খল ছতরদর লঞচত বরল নজর সথপন সবপনর সনর বল গডর সমপরণ পরপনথ মননয পরধনমনতর শকষক শকষরথর মলত আরতনদ যশরর আকশ বতস পরকমপত বসরর বসর একজন করমচর পরশসনর ছতরছযয অনযয পরতকর আজও ন জবনর সনল সময গল কলস পরকষ দয যশর বশববদযলয বনধ সপতহ যবত কতটক সময পরল সরয দখব শকষক লঞচত হল ছতর লঞচত হল ছতরদর জবন বপনন সহযয পব অনগরহ সবপন গল বচত এগয আসন সদষটর পথ পন গনছ আমর বনত ম নসর উদদন বদল জন পরকশল জব পরযকত বভগ যশর বজঞন পরযকত বশববদযলয'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "72f05cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sentiment labels to numerical values\n",
    "label_map  = {'happy': 0, 'angry': 1, 'fear': 2, 'disgust': 3, 'sad': 4, 'surprise': 5}\n",
    "y = df['Status'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a2109846",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b085da9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'বরবর মননয পরধনমনতর গণপরজতনতর বলদশ সরকর মননয পরধনমনতর সবপনর ডজটল বলদশর সবপন বক ললনকর একজন ছতর শত সহসর আশ দশর এক অকততম ভলবস নজক দশর যগয গড তলর এক তবর আকঙকষ ভরত হযছলম নজ হত পরতষঠত দশর অনযতম বশববদযলয যশর বজঞন পরযকত বশববদযলয ডজটল বলদশ গডত ধরণর পরযকত বশববদযলয পরতষঠ নসনদহ দশ পরচলনর বচকষণতর পরচয বহন কর যশর বসর সবপনর পরতষঠন শত শত টক বনযগ দহত উজড কর অতযনত দখর সথ বশববদযলয জবনর সচনলগন অনভব করছ য পওযর আননদ শকষরথদর মনপরন উজড পডলখ কথ বপরত কমলমত শকষরথর সদ দনতপত পরণ নশর হমক শললতহনর গলন ছতরতত বতল হমক নয সমমনত শকষকদর মরত যওয গল কট ফলর হমক পরণ নশর হমক কটকত নযমত ঘটন মননয পরধনমনতর শকষরথর শকষকদর পতমতর মত সমমন একজন চতরথ শরণর করমচরর শকষকদর নযমত ঘটনর শকর ডজটল বলদশর সবপন পক হনদর বহনর মত হন যয চখর ছতর বনর সললতহনর হয পরতবদ বহষকর শকষরথদর ভষ আনদলন মকতযদধর বভষকময গলর কথ সশসনর বলদশ আদরশ বশববদযলয বশববদযলযর পরশসনর পষ সনতরস মদক বযবসয শকষকদর লঞচত কর ছতরদর জবন ছনমন খল ছতরদর লঞচত বরল নজর সথপন সবপনর সনর বল গডর সমপরণ পরপনথ মননয পরধনমনতর শকষক শকষরথর মলত আরতনদ যশরর আকশ বতস পরকমপত বসরর বসর একজন করমচর পরশসনর ছতরছযয অনযয পরতকর আজও ন জবনর সনল সময গল কলস পরকষ দয যশর বশববদযলয বনধ সপতহ যবত কতটক সময পরল সরয দখব শকষক লঞচত হল ছতর লঞচত হল ছতরদর জবন বপনন সহযয পব অনগরহ সবপন গল বচত এগয আসন সদষটর পথ পন গনছ আমর বনত ম নসর উদদন বদল জন পরকশল জব পরযকত বভগ যশর বজঞন পরযকত বশববদযলয'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "eacbcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the number of features as needed\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b944b3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ed4a45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf.shape: (5031, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_tfidf.shape:\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "782bbd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5031, 5000) (1258, 5000)\n"
     ]
    }
   ],
   "source": [
    "# print(X_train, X_test, y_train, y_test)\n",
    "print(X_train_tfidf.shape, X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bd60ebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=6)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 6  # Number of neighbors (you can choose a different value)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_classifier.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c6d979e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_classifier.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4a190d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34340222575516693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.97      0.49       391\n",
      "           1       0.61      0.09      0.15       268\n",
      "           2       0.14      0.02      0.03        66\n",
      "           3       0.00      0.00      0.00       141\n",
      "           4       0.56      0.08      0.14       278\n",
      "           5       0.45      0.04      0.08       114\n",
      "\n",
      "    accuracy                           0.34      1258\n",
      "   macro avg       0.35      0.20      0.15      1258\n",
      "weighted avg       0.40      0.34      0.23      1258\n",
      "\n",
      "Confusion Matrix:\n",
      "[[380   3   0   0   4   4]\n",
      " [235  23   3   2   4   1]\n",
      " [ 62   1   1   0   2   0]\n",
      " [133   1   1   0   5   1]\n",
      " [246   6   2   1  23   0]\n",
      " [102   4   0   0   3   5]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db8bb0",
   "metadata": {},
   "source": [
    "# Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d1623e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded your dataset into a pandas DataFrame named 'df'\n",
    "# X should contain the features (in this case, the 'Sentence' column) and y should contain the target class labels (the 'Status' column)\n",
    "X = df['Sentence']\n",
    "y = df['Status']\n",
    "\n",
    "# Create a TfidfVectorizer to convert text to numerical features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Create an instance of the SMOTE class\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class (fear)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_vectorized, y)\n",
    "\n",
    "label_map  = {'happy': 0, 'angry': 1, 'fear': 2, 'disgust': 3, 'sad': 4, 'surprise': 5}\n",
    "y_resampled = y_resampled.map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f82ceaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled = X_resampled.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bf7831ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a86db889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5730533683289589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.43      0.41       390\n",
      "           1       0.92      0.22      0.36       384\n",
      "           2       0.94      0.93      0.93       374\n",
      "           3       0.92      0.60      0.73       388\n",
      "           4       0.41      0.51      0.45       393\n",
      "           5       0.42      0.78      0.55       357\n",
      "\n",
      "    accuracy                           0.57      2286\n",
      "   macro avg       0.67      0.58      0.57      2286\n",
      "weighted avg       0.67      0.57      0.57      2286\n",
      "\n",
      "Confusion Matrix:\n",
      "[[167   1   6   3 110 103]\n",
      " [ 65  85   3   6  98 127]\n",
      " [  4   0 346   0  13  11]\n",
      " [ 46   3   4 234  42  59]\n",
      " [ 91   2   5  12 199  84]\n",
      " [ 51   1   3   0  23 279]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Train the classifier\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a9cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
